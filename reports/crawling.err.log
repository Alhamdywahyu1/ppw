Traceback (most recent call last):
  File "/home/codespace/.local/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/asyncio/base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import requests
import pandas as pd

def get_springer_articles():
    # Silahkan membuat api key dari https://dev.springernature.com/#api
    api_key = "2def46e8e42b4d8e38abfc96e27b31d5"
    
    url = "https://api.springernature.com/meta/v2/json"
    params = {
        "q": "web mining,web usage mining",
        "api_key": api_key,
        "p": 10  # Jumlah artikel yang ingin diambil
    }

    # Siapkan dictionary untuk menampung data
    data_tabel = {
        "DOI": [],
        "Title": [],
        "Abstract": []
    }

    try:
        response = requests.get(url, params=params)
        response.raise_for_status()  # Ini akan menampilkan error jika request gagal

        data = response.json()
        
        print(f"Total hasil yang ditemukan: {data.get('result', [{}])[0].get('total', 'N/A')}\n")

        # Mengisi dictionary dengan data dari API
        for record in data.get('records', []):
            data_tabel["DOI"].append(record.get('doi', 'N/A'))
            data_tabel["Title"].append(record.get('title', 'No title'))
            
            # Mengambil abstrak dan membersihkannya dari tag HTML
            abstract_raw = record.get('abstract', 'No abstract')
            soup = BeautifulSoup(abstract_raw, 'html.parser')
            abstract_clean = soup.get_text()
            data_tabel["Abstract"].append(abstract_clean)

    except requests.exceptions.RequestException as e:
        print(f"Error saat mengakses API: {e}")
        return pd.DataFrame(data_tabel) # Mengembalikan DataFrame kosong jika error

    # MEKANISME PENYIMPANAN DAN TAMPILAN OUTPUT
    df = pd.DataFrame(data_tabel)
    df.to_csv("springer_articles.csv", index=False)
    
    # Menampilkan DataFrame
    print("--- Data Artikel dari Springer Nature ---")
    return df

# Menjalankan fungsi dan menampilkan hasilnya
get_springer_articles()
------------------

----- stdout -----
Total hasil yang ditemukan: 1276
------------------

[31m---------------------------------------------------------------------------[39m
[31mNameError[39m                                 Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[2][39m[32m, line 54[39m
[32m     51[39m     [38;5;28;01mreturn[39;00m df
[32m     53[39m [38;5;66;03m# Menjalankan fungsi dan menampilkan hasilnya[39;00m
[32m---> [39m[32m54[39m [43mget_springer_articles[49m[43m([49m[43m)[49m

[36mCell[39m[36m [39m[32mIn[2][39m[32m, line 37[39m, in [36mget_springer_articles[39m[34m()[39m
[32m     35[39m [38;5;66;03m# Mengambil abstrak dan membersihkannya dari tag HTML[39;00m
[32m     36[39m abstract_raw = record.get([33m'[39m[33mabstract[39m[33m'[39m, [33m'[39m[33mNo abstract[39m[33m'[39m)
[32m---> [39m[32m37[39m soup = [43mBeautifulSoup[49m(abstract_raw, [33m'[39m[33mhtml.parser[39m[33m'[39m)
[32m     38[39m abstract_clean = soup.get_text()
[32m     39[39m data_tabel[[33m"[39m[33mAbstract[39m[33m"[39m].append(abstract_clean)

[31mNameError[39m: name 'BeautifulSoup' is not defined

